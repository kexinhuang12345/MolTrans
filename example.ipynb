{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "from torch.utils import data\n",
    "from torch import nn \n",
    "import copy\n",
    "\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import time\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, f1_score, roc_curve, confusion_matrix, precision_score, recall_score, auc\n",
    "from sklearn.model_selection import KFold\n",
    "torch.manual_seed(2)    # reproducible torch:2 np:3\n",
    "np.random.seed(3)\n",
    "\n",
    "from config import BIN_config_DBPE\n",
    "from models import BIN_Interaction_Flat\n",
    "from stream import BIN_Data_Encoder\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(data_generator, model):\n",
    "    y_pred = []\n",
    "    y_label = []\n",
    "    model.eval()\n",
    "    loss_accumulate = 0.0\n",
    "    count = 0.0\n",
    "    for i, (d, p, d_mask, p_mask, label) in enumerate(data_generator):\n",
    "        score, _ = model(d.long().cuda(), p.long().cuda(), d_mask.long().cuda(), p_mask.long().cuda())\n",
    "        \n",
    "        m = torch.nn.Sigmoid()\n",
    "        logits = torch.squeeze(m(score))\n",
    "        loss_fct = torch.nn.BCELoss()            \n",
    "        \n",
    "        label = Variable(torch.from_numpy(np.array(label)).float()).cuda()\n",
    "\n",
    "        loss = loss_fct(logits, label)\n",
    "        \n",
    "        loss_accumulate += loss\n",
    "        count += 1\n",
    "        \n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        \n",
    "        label_ids = label.to('cpu').numpy()\n",
    "        y_label = y_label + label_ids.flatten().tolist()\n",
    "        y_pred = y_pred + logits.flatten().tolist()\n",
    "        \n",
    "    loss = loss_accumulate/count\n",
    "    \n",
    "    fpr, tpr, thresholds = roc_curve(y_label, y_pred)\n",
    "\n",
    "    precision = tpr / (tpr + fpr)\n",
    "\n",
    "    f1 = 2 * precision * tpr / (tpr + precision + 0.00001)\n",
    "\n",
    "    thred_optim = thresholds[5:][np.argmax(f1[5:])]\n",
    "\n",
    "    print(\"optimal threshold: \" + str(thred_optim))\n",
    "\n",
    "    y_pred_s = [1 if i else 0 for i in (y_pred >= thred_optim)]\n",
    "\n",
    "    auc_k = auc(fpr, tpr)\n",
    "    print(\"AUROC:\" + str(auc_k))\n",
    "    print(\"AUPRC: \"+ str(average_precision_score(y_label, y_pred)))\n",
    "\n",
    "    cm1 = confusion_matrix(y_label, y_pred_s)\n",
    "    print('Confusion Matrix : \\n', cm1)\n",
    "    print('Recall : ', recall_score(y_label, y_pred_s))\n",
    "    print('Precision : ', precision_score(y_label, y_pred_s))\n",
    "\n",
    "    total1=sum(sum(cm1))\n",
    "    #####from confusion matrix calculate accuracy\n",
    "    accuracy1=(cm1[0,0]+cm1[1,1])/total1\n",
    "    print ('Accuracy : ', accuracy1)\n",
    "\n",
    "    sensitivity1 = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
    "    print('Sensitivity : ', sensitivity1 )\n",
    "\n",
    "    specificity1 = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n",
    "    print('Specificity : ', specificity1)\n",
    "\n",
    "    outputs = np.asarray([1 if i else 0 for i in (np.asarray(y_pred) >= 0.5)])\n",
    "    return roc_auc_score(y_label, y_pred), average_precision_score(y_label, y_pred), f1_score(y_label, outputs), y_pred, loss.item()\n",
    "\n",
    "\n",
    "def main(fold_n, lr):\n",
    "    config = BIN_config_DBPE()\n",
    "    \n",
    "    lr = lr\n",
    "    BATCH_SIZE = config['batch_size']\n",
    "    train_epoch = 100\n",
    "    \n",
    "    loss_history = []\n",
    "    \n",
    "    model = BIN_Interaction_Flat(**config)\n",
    "    \n",
    "    model = model.cuda()\n",
    "\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "        model = nn.DataParallel(model, dim = 0)\n",
    "            \n",
    "    opt = torch.optim.Adam(model.parameters(), lr = lr)\n",
    "    #opt = torch.optim.SGD(model.parameters(), lr = lr, momentum=0.9)\n",
    "    \n",
    "    print('--- Data Preparation ---')\n",
    "    \n",
    "    params = {'batch_size': BATCH_SIZE,\n",
    "              'shuffle': True,\n",
    "              'num_workers': 6, \n",
    "              'drop_last': True}\n",
    "\n",
    "    dataFolder = './dataset/BindingDB'\n",
    "    df_train = pd.read_csv(dataFolder + '/train.csv')\n",
    "    df_val = pd.read_csv(dataFolder + '/val.csv')\n",
    "    df_test = pd.read_csv(dataFolder + '/test.csv')\n",
    "    \n",
    "    training_set = BIN_Data_Encoder(df_train.index.values, df_train.Label.values, df_train)\n",
    "    training_generator = data.DataLoader(training_set, **params)\n",
    "\n",
    "    validation_set = BIN_Data_Encoder(df_val.index.values, df_val.Label.values, df_val)\n",
    "    validation_generator = data.DataLoader(validation_set, **params)\n",
    "    \n",
    "    testing_set = BIN_Data_Encoder(df_test.index.values, df_test.Label.values, df_test)\n",
    "    testing_generator = data.DataLoader(testing_set, **params)\n",
    "    \n",
    "    # early stopping\n",
    "    max_auc = 0\n",
    "    model_max = copy.deepcopy(model)\n",
    "    \n",
    "    print('--- Go for Training ---')\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    for epo in range(train_epoch):\n",
    "        model.train()\n",
    "        for i, (d, p, d_mask, p_mask, label) in enumerate(training_generator):\n",
    "            score, _ = model(d.long().cuda(), p.long().cuda(), d_mask.long().cuda(), p_mask.long().cuda())\n",
    "\n",
    "            label = Variable(torch.from_numpy(np.array(label)).float()).cuda()\n",
    "            \n",
    "            loss_fct = torch.nn.BCELoss()\n",
    "            m = torch.nn.Sigmoid()\n",
    "            n = torch.squeeze(m(score))\n",
    "            \n",
    "            loss = loss_fct(n, label)\n",
    "            loss_history.append(loss)\n",
    "            \n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            \n",
    "            if (i % 100 == 0):\n",
    "                print('Training at Epoch ' + str(epo + 1) + ' iteration ' + str(i) + ' with loss ' + str(loss.cpu().detach().numpy()))\n",
    "            \n",
    "        # every epoch test\n",
    "        with torch.set_grad_enabled(False):\n",
    "            auc, auprc, f1, logits, loss = test(validation_generator, model)\n",
    "            if auc > max_auc:\n",
    "                model_max = copy.deepcopy(model)\n",
    "                max_auc = auc\n",
    "            \n",
    "            print('Validation at Epoch '+ str(epo + 1) + ' , AUROC: '+ str(auc) + ' , AUPRC: ' + str(auprc) + ' , F1: '+str(f1))\n",
    "    \n",
    "    print('--- Go for Testing ---')\n",
    "    try:\n",
    "        with torch.set_grad_enabled(False):\n",
    "            auc, auprc, f1, logits, loss = test(testing_generator, model_max)\n",
    "            print('Testing AUROC: ' + str(auc) + ' , AUPRC: ' + str(auprc) + ' , F1: '+str(f1) + ' , Test loss: '+str(loss))\n",
    "    except:\n",
    "        print('testing failed')\n",
    "    return model_max, loss_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's use 8 GPUs!\n",
      "--- Data Preparation ---\n",
      "--- Go for Training ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ken/miniconda3/envs/MolTrans/lib/python3.7/site-packages/torch/nn/parallel/data_parallel.py:30: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 0 which\n",
      "    has less than 75% of the memory or cores of GPU 1. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training at Epoch 1 iteration 0 with loss 0.67082864\n",
      "Training at Epoch 1 iteration 100 with loss 0.69454414\n",
      "Training at Epoch 1 iteration 200 with loss 0.68584555\n",
      "Training at Epoch 1 iteration 300 with loss 0.65992177\n",
      "Training at Epoch 1 iteration 400 with loss 0.7050383\n",
      "Training at Epoch 1 iteration 500 with loss 0.68235034\n",
      "Training at Epoch 1 iteration 600 with loss 0.66636235\n",
      "Training at Epoch 1 iteration 700 with loss 0.7001598\n",
      "optimal threshold: 0.07315666973590851\n",
      "AUROC:0.5709169097763743\n",
      "AUPRC: 0.17622596167517443\n",
      "Confusion Matrix : \n",
      " [[   0 5714]\n",
      " [   0  926]]\n",
      "Recall :  1.0\n",
      "Precision :  0.1394578313253012\n",
      "Accuracy :  0.1394578313253012\n",
      "Sensitivity :  0.0\n",
      "Specificity :  1.0\n",
      "Validation at Epoch 1 , AUROC: 0.5709169097763743 , AUPRC: 0.17622596167517443 , F1: 0.2542313117066291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ken/miniconda3/envs/MolTrans/lib/python3.7/site-packages/ipykernel_launcher.py:31: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training at Epoch 2 iteration 0 with loss 0.7192378\n",
      "Training at Epoch 2 iteration 100 with loss 0.7564486\n",
      "Training at Epoch 2 iteration 200 with loss 0.68028253\n",
      "Training at Epoch 2 iteration 300 with loss 0.6746302\n",
      "Training at Epoch 2 iteration 400 with loss 0.6865299\n",
      "Training at Epoch 2 iteration 500 with loss 0.71370286\n",
      "Training at Epoch 2 iteration 600 with loss 0.68855023\n",
      "Training at Epoch 2 iteration 700 with loss 0.7352923\n",
      "optimal threshold: 3.7331603380152956e-05\n",
      "AUROC:0.5987548297501268\n",
      "AUPRC: 0.19717487997919692\n",
      "Confusion Matrix : \n",
      " [[   0 5714]\n",
      " [   0  926]]\n",
      "Recall :  1.0\n",
      "Precision :  0.1394578313253012\n",
      "Accuracy :  0.1394578313253012\n",
      "Sensitivity :  0.0\n",
      "Specificity :  1.0\n",
      "Validation at Epoch 2 , AUROC: 0.5987548297501268 , AUPRC: 0.19717487997919692 , F1: 0.2620274914089347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ken/miniconda3/envs/MolTrans/lib/python3.7/site-packages/ipykernel_launcher.py:31: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training at Epoch 3 iteration 0 with loss 0.6567126\n",
      "Training at Epoch 3 iteration 100 with loss 0.67624635\n",
      "Training at Epoch 3 iteration 200 with loss 0.71628416\n",
      "Training at Epoch 3 iteration 300 with loss 0.6761807\n",
      "Training at Epoch 3 iteration 400 with loss 0.6982836\n",
      "Training at Epoch 3 iteration 500 with loss 0.71921015\n",
      "Training at Epoch 3 iteration 600 with loss 0.7202301\n",
      "Training at Epoch 3 iteration 700 with loss 0.6918887\n",
      "optimal threshold: 3.6369015438131314e-11\n",
      "AUROC:0.6178995047348437\n",
      "AUPRC: 0.21095644156146942\n",
      "Confusion Matrix : \n",
      " [[   1 5712]\n",
      " [   0  927]]\n",
      "Recall :  1.0\n",
      "Precision :  0.1396294622684139\n",
      "Accuracy :  0.13975903614457832\n",
      "Sensitivity :  0.00017503938386136881\n",
      "Specificity :  1.0\n",
      "Validation at Epoch 3 , AUROC: 0.6178995047348437 , AUPRC: 0.21095644156146942 , F1: 0.27842333105490996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ken/miniconda3/envs/MolTrans/lib/python3.7/site-packages/ipykernel_launcher.py:31: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training at Epoch 4 iteration 0 with loss 0.7050623\n",
      "Training at Epoch 4 iteration 100 with loss 0.6907485\n",
      "Training at Epoch 4 iteration 200 with loss 0.6963889\n",
      "Training at Epoch 4 iteration 300 with loss 0.6957656\n",
      "Training at Epoch 4 iteration 400 with loss 0.6684682\n",
      "Training at Epoch 4 iteration 500 with loss 0.68866754\n",
      "Training at Epoch 4 iteration 600 with loss 0.72337866\n",
      "Training at Epoch 4 iteration 700 with loss 0.72578484\n",
      "optimal threshold: 0.4688915014266968\n",
      "AUROC:0.620866959609087\n",
      "AUPRC: 0.19764261937762512\n",
      "Confusion Matrix : \n",
      " [[1245 4471]\n",
      " [  83  841]]\n",
      "Recall :  0.9101731601731602\n",
      "Precision :  0.15832078313253012\n",
      "Accuracy :  0.3141566265060241\n",
      "Sensitivity :  0.21780965710286915\n",
      "Specificity :  0.9101731601731602\n",
      "Validation at Epoch 4 , AUROC: 0.620866959609087 , AUPRC: 0.19764261937762512 , F1: 0.28085310328300983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ken/miniconda3/envs/MolTrans/lib/python3.7/site-packages/ipykernel_launcher.py:31: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training at Epoch 5 iteration 0 with loss 0.70766497\n",
      "Training at Epoch 5 iteration 100 with loss 0.65859604\n",
      "Training at Epoch 5 iteration 200 with loss 0.65823483\n",
      "Training at Epoch 5 iteration 300 with loss 0.69431573\n",
      "Training at Epoch 5 iteration 400 with loss 0.70292634\n",
      "Training at Epoch 5 iteration 500 with loss 0.71530986\n",
      "Training at Epoch 5 iteration 600 with loss 0.6983434\n",
      "Training at Epoch 5 iteration 700 with loss 0.6781969\n",
      "optimal threshold: 0.4660532474517822\n",
      "AUROC:0.6296021243398967\n",
      "AUPRC: 0.22324799154656727\n",
      "Confusion Matrix : \n",
      " [[ 592 5121]\n",
      " [  46  881]]\n",
      "Recall :  0.9503775620280475\n",
      "Precision :  0.14678440519826724\n",
      "Accuracy :  0.22183734939759037\n",
      "Sensitivity :  0.10362331524593034\n",
      "Specificity :  0.9503775620280475\n",
      "Validation at Epoch 5 , AUROC: 0.6296021243398967 , AUPRC: 0.22324799154656727 , F1: 0.2741742936729009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ken/miniconda3/envs/MolTrans/lib/python3.7/site-packages/ipykernel_launcher.py:31: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training at Epoch 6 iteration 0 with loss 0.7039902\n",
      "Training at Epoch 6 iteration 100 with loss 0.7233455\n",
      "Training at Epoch 6 iteration 200 with loss 0.73803186\n",
      "Training at Epoch 6 iteration 300 with loss 0.67067516\n",
      "Training at Epoch 6 iteration 400 with loss 0.6885591\n",
      "Training at Epoch 6 iteration 500 with loss 0.7188779\n",
      "Training at Epoch 6 iteration 600 with loss 0.66856825\n",
      "Training at Epoch 6 iteration 700 with loss 0.69552326\n",
      "optimal threshold: 0.43776440620422363\n",
      "AUROC:0.6239582843572381\n",
      "AUPRC: 0.206099660428421\n",
      "Confusion Matrix : \n",
      " [[ 275 5438]\n",
      " [  14  913]]\n",
      "Recall :  0.9848975188781014\n",
      "Precision :  0.1437568886789482\n",
      "Accuracy :  0.1789156626506024\n",
      "Sensitivity :  0.048135830561876425\n",
      "Specificity :  0.9848975188781014\n",
      "Validation at Epoch 6 , AUROC: 0.6239582843572381 , AUPRC: 0.206099660428421 , F1: 0.28043282236248873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ken/miniconda3/envs/MolTrans/lib/python3.7/site-packages/ipykernel_launcher.py:31: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training at Epoch 7 iteration 0 with loss 0.6819896\n",
      "Training at Epoch 7 iteration 100 with loss 0.6983069\n",
      "Training at Epoch 7 iteration 200 with loss 0.7219417\n",
      "Training at Epoch 7 iteration 300 with loss 0.69254005\n",
      "Training at Epoch 7 iteration 400 with loss 0.7024156\n",
      "Training at Epoch 7 iteration 500 with loss 0.71235186\n",
      "Training at Epoch 7 iteration 600 with loss 0.6606362\n",
      "Training at Epoch 7 iteration 700 with loss 0.6493866\n",
      "optimal threshold: 0.4446001946926117\n",
      "AUROC:0.6171993471993982\n",
      "AUPRC: 0.2271743894482957\n",
      "Confusion Matrix : \n",
      " [[ 321 5392]\n",
      " [  24  903]]\n",
      "Recall :  0.9741100323624595\n",
      "Precision :  0.14344718030182685\n",
      "Accuracy :  0.18433734939759036\n",
      "Sensitivity :  0.05618764221949939\n",
      "Specificity :  0.9741100323624595\n",
      "Validation at Epoch 7 , AUROC: 0.6171993471993982 , AUPRC: 0.2271743894482957 , F1: 0.2688836104513064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ken/miniconda3/envs/MolTrans/lib/python3.7/site-packages/ipykernel_launcher.py:31: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training at Epoch 8 iteration 0 with loss 0.69071335\n",
      "Training at Epoch 8 iteration 100 with loss 0.6409137\n",
      "Training at Epoch 8 iteration 200 with loss 0.6385876\n",
      "Training at Epoch 8 iteration 300 with loss 0.6805055\n",
      "Training at Epoch 8 iteration 400 with loss 0.700977\n",
      "Training at Epoch 8 iteration 500 with loss 0.6853907\n",
      "Training at Epoch 8 iteration 600 with loss 0.676106\n",
      "Training at Epoch 8 iteration 700 with loss 0.7196401\n",
      "optimal threshold: 0.41210272908210754\n",
      "AUROC:0.6235056218253677\n",
      "AUPRC: 0.2235906071800078\n",
      "Confusion Matrix : \n",
      " [[  25 5689]\n",
      " [   0  926]]\n",
      "Recall :  1.0\n",
      "Precision :  0.1399848828420257\n",
      "Accuracy :  0.14322289156626505\n",
      "Sensitivity :  0.004375218760938047\n",
      "Specificity :  1.0\n",
      "Validation at Epoch 8 , AUROC: 0.6235056218253677 , AUPRC: 0.2235906071800078 , F1: 0.27739188886399285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ken/miniconda3/envs/MolTrans/lib/python3.7/site-packages/ipykernel_launcher.py:31: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training at Epoch 9 iteration 0 with loss 0.65416056\n",
      "Training at Epoch 9 iteration 100 with loss 0.71033823\n",
      "Training at Epoch 9 iteration 200 with loss 0.7441087\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_721478/2352707113.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#biosnap interaction times 1e-6, flat, batch size 64, len 205, channel 3, epoch 50\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel_max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_history\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5e-6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0me\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_721478/2946748442.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m(fold_n, lr)\u001b[0m\n\u001b[1;32m    115\u001b[0m             \u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mloss_fct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBCELoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# fold 1\n",
    "#biosnap interaction times 1e-6, flat, batch size 64, len 205, channel 3, epoch 50\n",
    "s = time()\n",
    "model_max, loss_history = main(1, 5e-6)\n",
    "e = time()\n",
    "print(e-s)\n",
    "lh = list(filter(lambda x: x < 1, loss_history))\n",
    "plt.plot(lh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
